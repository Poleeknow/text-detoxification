{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models**\n",
    "## Fine tune `mrm8488/t5-small-finetuned-quora-for-paraphrasing`\n",
    "## [Link for the model](https://huggingface.co/mrm8488/t5-small-finetuned-quora-for-paraphrasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "5  I'm not gonna have a child... ...with the same...   \n",
       "6  They're all laughing at us, so we'll kick your...   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "5  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n",
       "6            they're laughing at us. We'll show you.    0.618866     0.230769   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  \n",
       "5  0.950956  0.035846  \n",
       "6  0.999492  0.000131  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data from a CSV file\n",
    "data = pd.read_csv(\"filtered_paranmt/filtered.tsv\", sep=\"\\t\", index_col=0)\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that is used to prepare the data for model\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_source_length, max_target_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def priint(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        print(row[\"Toxic\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            row[\"Toxic\"]\n",
    "        )\n",
    "        outputs = self.tokenizer(\n",
    "            row[\"Neutral\"]\n",
    "        )\n",
    "        inputs[\"input_ids\"] = torch.tensor(inputs[\"input_ids\"])\n",
    "        inputs[\"attention_mask\"] = torch.tensor(inputs[\"attention_mask\"])\n",
    "        inputs[\"labels\"] = torch.tensor(outputs[\"input_ids\"])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Tox score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if alkar floods her with her mental waste it w...</td>\n",
       "      <td>if alkar is flooding her with psychic waste th...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youre becoming disgusting</td>\n",
       "      <td>now youre getting nasty</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well we can spare your life</td>\n",
       "      <td>well we could spare your life for one</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey you have to wake up</td>\n",
       "      <td>ah monkey youve got to snap out of it</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have orders to kill her</td>\n",
       "      <td>ive got orders to put her down</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557503</th>\n",
       "      <td>you didnt know that estelle stole your fish fr...</td>\n",
       "      <td>you didnt know that estelle had stolen some fi...</td>\n",
       "      <td>0.949143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557504</th>\n",
       "      <td>itil suck the life out of you</td>\n",
       "      <td>youd be sucked out of your life</td>\n",
       "      <td>0.996124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557505</th>\n",
       "      <td>i cant fuckin take that bruv</td>\n",
       "      <td>i really cant take this</td>\n",
       "      <td>0.984538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557506</th>\n",
       "      <td>they called me a fucking hero the truth is i d...</td>\n",
       "      <td>they said i was a hero but i didnt care</td>\n",
       "      <td>0.991945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557507</th>\n",
       "      <td>i didnt fuck him</td>\n",
       "      <td>i did not screw him</td>\n",
       "      <td>0.994174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Toxic  \\\n",
       "0       if alkar floods her with her mental waste it w...   \n",
       "1                               youre becoming disgusting   \n",
       "2                             well we can spare your life   \n",
       "3                              monkey you have to wake up   \n",
       "4                               i have orders to kill her   \n",
       "...                                                   ...   \n",
       "557503  you didnt know that estelle stole your fish fr...   \n",
       "557504                      itil suck the life out of you   \n",
       "557505                       i cant fuckin take that bruv   \n",
       "557506  they called me a fucking hero the truth is i d...   \n",
       "557507                                   i didnt fuck him   \n",
       "\n",
       "                                                  Neutral  Tox score  \n",
       "0       if alkar is flooding her with psychic waste th...   0.981983  \n",
       "1                                 now youre getting nasty   0.999039  \n",
       "2                   well we could spare your life for one   0.985068  \n",
       "3                   ah monkey youve got to snap out of it   0.994215  \n",
       "4                          ive got orders to put her down   0.999348  \n",
       "...                                                   ...        ...  \n",
       "557503  you didnt know that estelle had stolen some fi...   0.949143  \n",
       "557504                    youd be sucked out of your life   0.996124  \n",
       "557505                            i really cant take this   0.984538  \n",
       "557506            they said i was a hero but i didnt care   0.991945  \n",
       "557507                                i did not screw him   0.994174  \n",
       "\n",
       "[557508 rows x 3 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data \n",
    "input_data = pd.read_csv(\"filtered_for_models.csv\", index_col=0)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, val_set = train_test_split(input_data[:1000], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84907\\Desktop\\Иннополис\\Practical ML & DL\\Ass1\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "c:\\Users\\84907\\Desktop\\Иннополис\\Practical ML & DL\\Ass1\\.venv\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1509: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer from pretrained\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-small-finetuned-quora-for-paraphrasing\", cache_dir=None)\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-small-finetuned-quora-for-paraphrasing\", cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recollect data to fit for the model\n",
    "train_dataset = MyDataset(train_set, tokenizer, 128, 128)\n",
    "val_dataset = MyDataset(val_set, tokenizer, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and im not just talking about hitting me for your boyfriend what a girl\n"
     ]
    }
   ],
   "source": [
    "train_dataset.priint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=124,\n",
    "    per_device_eval_batch_size=124,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=300,\n",
    "    logging_steps=50,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 14/14 [12:04<00:00, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 724.1687, 'train_samples_per_second': 2.209, 'train_steps_per_second': 0.019, 'train_loss': 3.4641502925327847, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=3.4641502925327847, metrics={'train_runtime': 724.1687, 'train_samples_per_second': 2.209, 'train_steps_per_second': 0.019, 'train_loss': 3.4641502925327847, 'epoch': 2.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"t5smallparaph.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text, max_length=128):\n",
    "\n",
    "  input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  generated_ids = model.generate(input_ids=input_ids, num_return_sequences=5, num_beams=5, max_length=max_length, no_repeat_ngram_size=2, repetition_penalty=3.5, length_penalty=1.0, early_stopping=True)\n",
    "\n",
    "  preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "\n",
    "  return preds\n",
    "  \n",
    "preds = paraphrase(\"paraphrase: What is the best framework for dealing with a huge text dataset?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Tox score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535150</th>\n",
       "      <td>ill ill smash it myself</td>\n",
       "      <td>i broke it myself</td>\n",
       "      <td>0.971542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444270</th>\n",
       "      <td>the tits</td>\n",
       "      <td>those boobies</td>\n",
       "      <td>0.984656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208888</th>\n",
       "      <td>but hes fucking captain america</td>\n",
       "      <td>hes captain america</td>\n",
       "      <td>0.998577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478355</th>\n",
       "      <td>if he gets another chance im dead</td>\n",
       "      <td>if he ever got a second chance i was dead</td>\n",
       "      <td>0.963460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316261</th>\n",
       "      <td>basically these two are real criminals</td>\n",
       "      <td>actually those are the real criminals over there</td>\n",
       "      <td>0.986255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335957</th>\n",
       "      <td>how dare you shoot at my wife</td>\n",
       "      <td>how dare you shoot my wife</td>\n",
       "      <td>0.978353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387628</th>\n",
       "      <td>no wonder kurtz put a weed up commands ass</td>\n",
       "      <td>no wonder kurtz had screwed up the command</td>\n",
       "      <td>0.996818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73151</th>\n",
       "      <td>so these boobs</td>\n",
       "      <td>so the breasts</td>\n",
       "      <td>0.991037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420809</th>\n",
       "      <td>this is junk again near california state unive...</td>\n",
       "      <td>and here is the flotsam near california state ...</td>\n",
       "      <td>0.971545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537234</th>\n",
       "      <td>i cant go around telling guys not to ask amy o...</td>\n",
       "      <td>i cant ban guys from asking amy out because i ...</td>\n",
       "      <td>0.980846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Toxic  \\\n",
       "535150                            ill ill smash it myself   \n",
       "444270                                           the tits   \n",
       "208888                    but hes fucking captain america   \n",
       "478355                  if he gets another chance im dead   \n",
       "316261             basically these two are real criminals   \n",
       "335957                      how dare you shoot at my wife   \n",
       "387628         no wonder kurtz put a weed up commands ass   \n",
       "73151                                      so these boobs   \n",
       "420809  this is junk again near california state unive...   \n",
       "537234  i cant go around telling guys not to ask amy o...   \n",
       "\n",
       "                                                  Neutral  Tox score  \n",
       "535150                                  i broke it myself   0.971542  \n",
       "444270                                      those boobies   0.984656  \n",
       "208888                                hes captain america   0.998577  \n",
       "478355          if he ever got a second chance i was dead   0.963460  \n",
       "316261   actually those are the real criminals over there   0.986255  \n",
       "335957                         how dare you shoot my wife   0.978353  \n",
       "387628         no wonder kurtz had screwed up the command   0.996818  \n",
       "73151                                      so the breasts   0.991037  \n",
       "420809  and here is the flotsam near california state ...   0.971545  \n",
       "537234  i cant ban guys from asking amy out because i ...   0.980846  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = input_data.sample(n=10)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paraphrased sentences from the model\n",
    "paraphrased = []\n",
    "for sent in test_sample['Toxic']:\n",
    "    paraph = paraphrase(sent)\n",
    "    paraphrased.append(paraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Is it okay to smash it myself?',\n",
       "  'Is it okay to smash it myself ill?',\n",
       "  'I ill smash it myself.',\n",
       "  'Is it okay to smash it myself.',\n",
       "  'Is it okay to smash it myself ill.'],\n",
       " ['What are the tits?',\n",
       "  'What are the tits and how do they work?',\n",
       "  'What are the tits and how do they look like?',\n",
       "  'What are the tits and how do they work out?',\n",
       "  'What are the tits and how do they get rid of?'],\n",
       " ['But hes fucking captain america.',\n",
       "  'Hes fucking captain america but hes not a big fan.',\n",
       "  'Hes fucking captain america but hes not a good guy.',\n",
       "  'Hes fucking captain america but hes not a bad guy.',\n",
       "  'Hes fucking captain america but hes not a good captain.'],\n",
       " ['If he gets another chance im dead.',\n",
       "  'if he gets another chance im dead.',\n",
       "  'If he gets another chance im dead in the next 10 years, and his chances are good.',\n",
       "  'If he gets another chance im dead in the next 10 years, and his chances are there.',\n",
       "  'If he gets another chance im dead in the next 10 years, if his chances are there.'],\n",
       " ['Basically these two are real criminals?',\n",
       "  'These two are real criminals?',\n",
       "  'Basically these two are real criminals.',\n",
       "  'Basically these two are real criminals and basically they are the same.',\n",
       "  'Basically these two are real criminals, and basically they are the same.'],\n",
       " ['How do you shoot at my wife?',\n",
       "  'How dare you shoot at my wife?',\n",
       "  'How do you shoot at your wife?',\n",
       "  'How do you shoot my wife at me?',\n",
       "  'How do you shoot my wife?'],\n",
       " ['No wonder kurtz put weed up commands ass.',\n",
       "  'No wonder kurtz put a weed up commands ass.',\n",
       "  'No wonder Kurtz put weed up commands ass.',\n",
       "  'No wonder kurtz put a weed up commands ass?',\n",
       "  'No wonder kurtz put a weed up commands ass no wonder.'],\n",
       " ['What are some of the boobs?',\n",
       "  'So these boobs are so cute.',\n",
       "  \"So these boobs are so good that they don't have to be.\",\n",
       "  \"So these boobs are so good that they don't have to.\",\n",
       "  \"So these boobs are so good that they don't need to be.\"],\n",
       " ['This is junk again near california state university long beach.',\n",
       "  'this is junk again near california state university long beach.',\n",
       "  'This is junk again near california state university long beach',\n",
       "  'This is junk again near california state university long beach this is trash in the past.',\n",
       "  'This is junk again near california state university long beach this is trash again in the area'],\n",
       " ['I cant go around telling guys not to ask amy out because i like her and im too dumb to do anything about it.',\n",
       "  \"I can't go around telling guys not to ask amy out because i like her and im too dumb to do anything about it.\",\n",
       "  'I cant go around telling guys not to ask amy out because i like her and im too dumb to do anything about it?',\n",
       "  'I cant go around telling guys not to ask amy out because i like her and im too dumb to do anything about it',\n",
       "  \"I can't go around telling guys not to ask amy out because i like her and im too dumb to do anything about it?\"]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appresiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kissoon</td>\n",
       "      <td>24170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ripton</td>\n",
       "      <td>21371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose-jointed</td>\n",
       "      <td>90238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skins</td>\n",
       "      <td>7531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seena</td>\n",
       "      <td>37526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113967</th>\n",
       "      <td>ﬁve</td>\n",
       "      <td>113966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113968</th>\n",
       "      <td>ﬂoat</td>\n",
       "      <td>113967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113969</th>\n",
       "      <td>ﬂoor</td>\n",
       "      <td>113969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113970</th>\n",
       "      <td>ﬂunkeys</td>\n",
       "      <td>113970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113971</th>\n",
       "      <td>ﬂy</td>\n",
       "      <td>113971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  key  translation\n",
       "0             kissoon        24170\n",
       "1              ripton        21371\n",
       "2       loose-jointed        90238\n",
       "3               skins         7531\n",
       "4               seena        37526\n",
       "...               ...          ...\n",
       "113967            ﬁve       113966\n",
       "113968           ﬂoat       113967\n",
       "113969           ﬂoor       113969\n",
       "113970        ﬂunkeys       113970\n",
       "113971             ﬂy       113971\n",
       "\n",
       "[113972 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocabulary\n",
    "vocabframe = pd.read_csv(\"bestvocab.csv\", index_col=0)\n",
    "vocabframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\84907\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preporation for metric model\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "ENGLISH_STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def text_to_tensor(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = sent.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    sent = \" \".join([word for word in str(sent).split() if word not in ENGLISH_STOPWORDS])\n",
    "    sent = word_tokenize(sent)\n",
    "\n",
    "    words = []\n",
    "    for word in sent:\n",
    "        query = list(vocabframe.query(\"key == @word\")['translation'])\n",
    "        if len(query) > 0:\n",
    "            words.append(query[0])\n",
    "    return torch.tensor(words, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is it okay to smash it myself?'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 151, 1445])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tensor(paraphrased[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextRegressionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        dout = self.dropout(embedded)\n",
    "        lstm_out, (ht, ct) = self.lstm(dout)\n",
    "        out = self.linear1(lstm_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        return self.linearOut(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metric model\n",
    "from torch import nn\n",
    "\n",
    "metric_model = TextRegressionModel(114506, 300, 200)\n",
    "cpt = torch.load(\"best.pt\")\n",
    "metric_model.load_state_dict(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset(sent):\n",
    "    offset = [0]\n",
    "    offset.append(sent.size(0))\n",
    "    offset = torch.tensor(offset[:-1]).cumsum(dim=0)\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model,\n",
    "    sent,\n",
    "    offset\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        output = model(sent, offset)\n",
    "        if output.item() > 1:\n",
    "            score = 1.0\n",
    "        else: score = output.item()\n",
    "\n",
    "    return round(score, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score paraphpased sentences\n",
    "predicted = []\n",
    "pred_scores = []\n",
    "for set5 in paraphrased:\n",
    "    best_score = 1.1\n",
    "    best = -1\n",
    "    for i, sent in enumerate(set5):\n",
    "        tokenized = text_to_tensor(sent)\n",
    "        offset = get_offset(tokenized)\n",
    "        score = predict(metric_model, tokenized, offset)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best = i\n",
    "    predicted.append(set5[best])\n",
    "    pred_scores.append(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Is it okay to smash it myself ill?', 'What are the tits?', 'Hes fucking captain america but hes not a bad guy.', 'If he gets another chance im dead.', 'Basically these two are real criminals and basically they are the same.', 'How dare you shoot at my wife?', 'No wonder kurtz put a weed up commands ass no wonder.', \"So these boobs are so good that they don't need to be.\", 'This is junk again near california state university long beach this is trash in the past.', 'I cant go around telling guys not to ask amy out because i like her and im too dumb to do anything about it.']\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_score = list(test_sample['Tox score'])\n",
    "inputs = list(test_sample['Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic style</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ill ill smash it myself</td>\n",
       "      <td>0.971542</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>Is it okay to smash it myself ill?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the tits</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>What are the tits?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but hes fucking captain america</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>Hes fucking captain america but hes not a bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if he gets another chance im dead</td>\n",
       "      <td>0.963460</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>If he gets another chance im dead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basically these two are real criminals</td>\n",
       "      <td>0.986255</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>Basically these two are real criminals and bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how dare you shoot at my wife</td>\n",
       "      <td>0.978353</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>How dare you shoot at my wife?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no wonder kurtz put a weed up commands ass</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>No wonder kurtz put a weed up commands ass no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so these boobs</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>So these boobs are so good that they don't nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this is junk again near california state unive...</td>\n",
       "      <td>0.971545</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>This is junk again near california state unive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i cant go around telling guys not to ask amy o...</td>\n",
       "      <td>0.980846</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>I cant go around telling guys not to ask amy o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Toxic style    Before   After  \\\n",
       "0                            ill ill smash it myself  0.971542  0.5256   \n",
       "1                                           the tits  0.984656  0.0423   \n",
       "2                    but hes fucking captain america  0.998577  0.0686   \n",
       "3                  if he gets another chance im dead  0.963460  0.2158   \n",
       "4             basically these two are real criminals  0.986255  0.9131   \n",
       "5                      how dare you shoot at my wife  0.978353  0.1601   \n",
       "6         no wonder kurtz put a weed up commands ass  0.996818  0.0491   \n",
       "7                                     so these boobs  0.991037  0.0404   \n",
       "8  this is junk again near california state unive...  0.971545  0.3608   \n",
       "9  i cant go around telling guys not to ask amy o...  0.980846  0.6521   \n",
       "\n",
       "                                         Translation  \n",
       "0                 Is it okay to smash it myself ill?  \n",
       "1                                 What are the tits?  \n",
       "2  Hes fucking captain america but hes not a bad ...  \n",
       "3                 If he gets another chance im dead.  \n",
       "4  Basically these two are real criminals and bas...  \n",
       "5                     How dare you shoot at my wife?  \n",
       "6  No wonder kurtz put a weed up commands ass no ...  \n",
       "7  So these boobs are so good that they don't nee...  \n",
       "8  This is junk again near california state unive...  \n",
       "9  I cant go around telling guys not to ask amy o...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the scores\n",
    "scores = pd.DataFrame(list(zip(inputs, input_score, pred_scores, predicted)), index=None, columns=['Toxic style', 'Before', 'After', 'Translation'])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
