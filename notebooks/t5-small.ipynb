{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models**\n",
    "## Fine tune `t5-small`\n",
    "## [Link for the model](https://huggingface.co/t5-small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "5  I'm not gonna have a child... ...with the same...   \n",
       "6  They're all laughing at us, so we'll kick your...   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "5  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n",
       "6            they're laughing at us. We'll show you.    0.618866     0.230769   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  \n",
       "5  0.950956  0.035846  \n",
       "6  0.999492  0.000131  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data from a CSV file\n",
    "data = pd.read_csv(\"filtered_paranmt/filtered.tsv\", sep=\"\\t\", index_col=0)\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that is used to prepare the data for model\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_source_length, max_target_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def priint(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        print(row[\"Toxic\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            row[\"Toxic\"]\n",
    "        )\n",
    "        outputs = self.tokenizer(\n",
    "            row[\"Neutral\"]\n",
    "        )\n",
    "        inputs[\"input_ids\"] = torch.tensor(inputs[\"input_ids\"])\n",
    "        inputs[\"attention_mask\"] = torch.tensor(inputs[\"attention_mask\"])\n",
    "        inputs[\"labels\"] = torch.tensor(outputs[\"input_ids\"])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Tox score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if alkar floods her with her mental waste it w...</td>\n",
       "      <td>if alkar is flooding her with psychic waste th...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youre becoming disgusting</td>\n",
       "      <td>now youre getting nasty</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well we can spare your life</td>\n",
       "      <td>well we could spare your life for one</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey you have to wake up</td>\n",
       "      <td>ah monkey youve got to snap out of it</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have orders to kill her</td>\n",
       "      <td>ive got orders to put her down</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557503</th>\n",
       "      <td>you didnt know that estelle stole your fish fr...</td>\n",
       "      <td>you didnt know that estelle had stolen some fi...</td>\n",
       "      <td>0.949143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557504</th>\n",
       "      <td>itil suck the life out of you</td>\n",
       "      <td>youd be sucked out of your life</td>\n",
       "      <td>0.996124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557505</th>\n",
       "      <td>i cant fuckin take that bruv</td>\n",
       "      <td>i really cant take this</td>\n",
       "      <td>0.984538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557506</th>\n",
       "      <td>they called me a fucking hero the truth is i d...</td>\n",
       "      <td>they said i was a hero but i didnt care</td>\n",
       "      <td>0.991945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557507</th>\n",
       "      <td>i didnt fuck him</td>\n",
       "      <td>i did not screw him</td>\n",
       "      <td>0.994174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Toxic  \\\n",
       "0       if alkar floods her with her mental waste it w...   \n",
       "1                               youre becoming disgusting   \n",
       "2                             well we can spare your life   \n",
       "3                              monkey you have to wake up   \n",
       "4                               i have orders to kill her   \n",
       "...                                                   ...   \n",
       "557503  you didnt know that estelle stole your fish fr...   \n",
       "557504                      itil suck the life out of you   \n",
       "557505                       i cant fuckin take that bruv   \n",
       "557506  they called me a fucking hero the truth is i d...   \n",
       "557507                                   i didnt fuck him   \n",
       "\n",
       "                                                  Neutral  Tox score  \n",
       "0       if alkar is flooding her with psychic waste th...   0.981983  \n",
       "1                                 now youre getting nasty   0.999039  \n",
       "2                   well we could spare your life for one   0.985068  \n",
       "3                   ah monkey youve got to snap out of it   0.994215  \n",
       "4                          ive got orders to put her down   0.999348  \n",
       "...                                                   ...        ...  \n",
       "557503  you didnt know that estelle had stolen some fi...   0.949143  \n",
       "557504                    youd be sucked out of your life   0.996124  \n",
       "557505                            i really cant take this   0.984538  \n",
       "557506            they said i was a hero but i didnt care   0.991945  \n",
       "557507                                i did not screw him   0.994174  \n",
       "\n",
       "[557508 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data \n",
    "input_data = pd.read_csv(\"filtered_for_models.csv\", index_col=0)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, val_set = train_test_split(input_data[:1000], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\84907\\desktop\\иннополис\\practical ml & dl\\ass1\\.venv\\lib\\site-packages (4.25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84907\\Desktop\\Иннополис\\Practical ML & DL\\Ass1\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\84907\\Desktop\\Иннополис\\Practical ML & DL\\Ass1\\.venv\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1509: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 36.4kB/s]\n",
      "c:\\Users\\84907\\Desktop\\Иннополис\\Practical ML & DL\\Ass1\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\84907\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer from pretrained\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=None)\n",
    "model = AutoModelWithLMHead.from_pretrained(\"t5-small\", cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recollect data to fit for the model\n",
    "train_dataset = MyDataset(train_set, tokenizer, 128, 128)\n",
    "val_dataset = MyDataset(val_set, tokenizer, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and im not just talking about hitting me for your boyfriend what a girl\n"
     ]
    }
   ],
   "source": [
    "train_dataset.priint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=124,\n",
    "    per_device_eval_batch_size=124,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=300,\n",
    "    logging_steps=50,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 14/14 [10:31<00:00, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 631.4419, 'train_samples_per_second': 2.534, 'train_steps_per_second': 0.022, 'train_loss': 3.337999071393694, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=3.337999071393694, metrics={'train_runtime': 631.4419, 'train_samples_per_second': 2.534, 'train_steps_per_second': 0.022, 'train_loss': 3.337999071393694, 'epoch': 2.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"t5small.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text, max_length=128):\n",
    "\n",
    "  input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  generated_ids = model.generate(input_ids=input_ids, num_return_sequences=5, num_beams=5, max_length=max_length, no_repeat_ngram_size=2, repetition_penalty=3.5, length_penalty=1.0, early_stopping=True)\n",
    "\n",
    "  preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Tox score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527382</th>\n",
       "      <td>i threw them all out</td>\n",
       "      <td>i had them all fired</td>\n",
       "      <td>0.908439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244993</th>\n",
       "      <td>the background is that our thing is cool and p...</td>\n",
       "      <td>the grounds are our thing is cool and popular ...</td>\n",
       "      <td>0.986022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70263</th>\n",
       "      <td>nothing yet but i want you to know i smell a rat</td>\n",
       "      <td>so far from nothing but i have rats smell</td>\n",
       "      <td>0.957481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206964</th>\n",
       "      <td>could you not appreciate what you fucking had</td>\n",
       "      <td>you couldnt be happy with what you had</td>\n",
       "      <td>0.998181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91515</th>\n",
       "      <td>your destruction is inevitable</td>\n",
       "      <td>your doom is inevitable</td>\n",
       "      <td>0.715417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86573</th>\n",
       "      <td>thats really fucked up</td>\n",
       "      <td>thats messed up man</td>\n",
       "      <td>0.999102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497696</th>\n",
       "      <td>were fucking free</td>\n",
       "      <td>we are home free</td>\n",
       "      <td>0.957807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399940</th>\n",
       "      <td>you were really sick and your mother wanted me...</td>\n",
       "      <td>you had been very ill and your mother wanted u...</td>\n",
       "      <td>0.973515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137356</th>\n",
       "      <td>a nice bowl of soup a little blow job from mél...</td>\n",
       "      <td>a good soup and a little something from melani...</td>\n",
       "      <td>0.991525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220875</th>\n",
       "      <td>shit clayton run</td>\n",
       "      <td>clayton run</td>\n",
       "      <td>0.999473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Toxic  \\\n",
       "527382                               i threw them all out   \n",
       "244993  the background is that our thing is cool and p...   \n",
       "70263    nothing yet but i want you to know i smell a rat   \n",
       "206964      could you not appreciate what you fucking had   \n",
       "91515                      your destruction is inevitable   \n",
       "86573                              thats really fucked up   \n",
       "497696                                  were fucking free   \n",
       "399940  you were really sick and your mother wanted me...   \n",
       "137356  a nice bowl of soup a little blow job from mél...   \n",
       "220875                                   shit clayton run   \n",
       "\n",
       "                                                  Neutral  Tox score  \n",
       "527382                               i had them all fired   0.908439  \n",
       "244993  the grounds are our thing is cool and popular ...   0.986022  \n",
       "70263           so far from nothing but i have rats smell   0.957481  \n",
       "206964             you couldnt be happy with what you had   0.998181  \n",
       "91515                             your doom is inevitable   0.715417  \n",
       "86573                                 thats messed up man   0.999102  \n",
       "497696                                   we are home free   0.957807  \n",
       "399940  you had been very ill and your mother wanted u...   0.973515  \n",
       "137356  a good soup and a little something from melani...   0.991525  \n",
       "220875                                        clayton run   0.999473  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = input_data.sample(n=10)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paraphrased sentences from the model\n",
    "paraphrased = []\n",
    "for sent in test_sample['Toxic']:\n",
    "    paraph = paraphrase(sent)\n",
    "    paraphrased.append(paraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['y', 'the', 'd', 'just', ''],\n",
       " ['Our thing is cool and popular and harvard connection sucks',\n",
       "  'Our thing is cool and popular and harvard connection sucks.',\n",
       "  'Our thing is cool and popular and harvard connection sucks!',\n",
       "  'Our thing is cool and popular and harvard connections sucks',\n",
       "  'our thing is cool and popular and harvard connection sucks'],\n",
       " ['i smell a rat.',\n",
       "  'i smell a rat',\n",
       "  'i smell a rat!',\n",
       "  'i smell a rat but nothing yet.',\n",
       "  \"i smell a rat but it's good.\"],\n",
       " ['Können Sie nicht wissen, was Sie gefuckt haben?',\n",
       "  'Können Sie nicht wissen, was Sie gefuckt hätten?',\n",
       "  'Können Sie nicht wissen, was Sie gefuckt haben hätte?',\n",
       "  'Können Sie nicht wissen, was Sie gefuckt hatten?',\n",
       "  'Können Sie nicht wissen, was Sie gefuckt hätte haben?'],\n",
       " ['your destruction destruction is inevitable',\n",
       "  'your destruction destruction is inevitable.',\n",
       "  'ura destruction destruction is inevitable',\n",
       "  'your destruction destruction is inevitable.',\n",
       "  'La destruction destruction is inevitable'],\n",
       " ['Dass really fucked up in the back.',\n",
       "  'Thats really fucked up.',\n",
       "  'Dass really fucked up in the back of it.',\n",
       "  'Thats really fucked up in the back of it.',\n",
       "  ''],\n",
       " ['fuck free', 'nuck free', 'tuck free', 'free', 'a'],\n",
       " ['you was really sick and your mother wanted me to talk to you',\n",
       "  'and you were really sick and your mother wanted me to talk to you.',\n",
       "  'and you were really sick and your mother wanted me to talk to you?',\n",
       "  'you was really sick and your mother wanted me to talk to you.',\n",
       "  'and you were really sick and your mother wanted me to talk to you!'],\n",
       " ['a little blow job from mélanie youll see',\n",
       "  'a little blow job from melanie youll see',\n",
       "  'a little blow job from melanie, youll see',\n",
       "  'melanie youll see',\n",
       "  'a little blow job from mélanie youll see the'],\n",
       " ['shit clayton run', 'Shit clayton run', '.', '-', '']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appresiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kissoon</td>\n",
       "      <td>24170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ripton</td>\n",
       "      <td>21371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose-jointed</td>\n",
       "      <td>90238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skins</td>\n",
       "      <td>7531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seena</td>\n",
       "      <td>37526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113967</th>\n",
       "      <td>ﬁve</td>\n",
       "      <td>113966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113968</th>\n",
       "      <td>ﬂoat</td>\n",
       "      <td>113967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113969</th>\n",
       "      <td>ﬂoor</td>\n",
       "      <td>113969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113970</th>\n",
       "      <td>ﬂunkeys</td>\n",
       "      <td>113970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113971</th>\n",
       "      <td>ﬂy</td>\n",
       "      <td>113971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  key  translation\n",
       "0             kissoon        24170\n",
       "1              ripton        21371\n",
       "2       loose-jointed        90238\n",
       "3               skins         7531\n",
       "4               seena        37526\n",
       "...               ...          ...\n",
       "113967            ﬁve       113966\n",
       "113968           ﬂoat       113967\n",
       "113969           ﬂoor       113969\n",
       "113970        ﬂunkeys       113970\n",
       "113971             ﬂy       113971\n",
       "\n",
       "[113972 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocabulary\n",
    "vocabframe = pd.read_csv(\"bestvocab.csv\", index_col=0)\n",
    "vocabframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\84907\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preporation for metric model\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "ENGLISH_STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def text_to_tensor(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = sent.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    sent = \" \".join([word for word in str(sent).split() if word not in ENGLISH_STOPWORDS])\n",
    "    sent = word_tokenize(sent)\n",
    "\n",
    "    words = []\n",
    "    for word in sent:\n",
    "        query = list(vocabframe.query(\"key == @word\")['translation'])\n",
    "        if len(query) > 0:\n",
    "            words.append(query[0])\n",
    "    return torch.tensor(words, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextRegressionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        dout = self.dropout(embedded)\n",
    "        lstm_out, (ht, ct) = self.lstm(dout)\n",
    "        out = self.linear1(lstm_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        return self.linearOut(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metric model\n",
    "from torch import nn\n",
    "\n",
    "metric_model = TextRegressionModel(114506, 300, 200)\n",
    "cpt = torch.load(\"best.pt\")\n",
    "metric_model.load_state_dict(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset(sent):\n",
    "    offset = [0]\n",
    "    offset.append(sent.size(0))\n",
    "    offset = torch.tensor(offset[:-1]).cumsum(dim=0)\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model,\n",
    "    sent,\n",
    "    offset\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        output = model(sent, offset)\n",
    "        if output.item() > 1:\n",
    "            score = 1.0\n",
    "        else: score = output.item()\n",
    "\n",
    "    return round(score, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score paraphpased sentences\n",
    "predicted = []\n",
    "pred_scores = []\n",
    "for set5 in paraphrased:\n",
    "    best_score = 1.1\n",
    "    best = -1\n",
    "    for i, sent in enumerate(set5):\n",
    "        tokenized = text_to_tensor(sent)\n",
    "        offset = get_offset(tokenized)\n",
    "        score = predict(metric_model, tokenized, offset)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best = i\n",
    "    predicted.append(set5[best])\n",
    "    pred_scores.append(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_score = list(test_sample['Tox score'])\n",
    "inputs = list(test_sample['Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic style</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i threw them all out</td>\n",
       "      <td>0.908439</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the background is that our thing is cool and p...</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>Our thing is cool and popular and harvard conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing yet but i want you to know i smell a rat</td>\n",
       "      <td>0.957481</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>i smell a rat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could you not appreciate what you fucking had</td>\n",
       "      <td>0.998181</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>Können Sie nicht wissen, was Sie gefuckt haben?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your destruction is inevitable</td>\n",
       "      <td>0.715417</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>your destruction destruction is inevitable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thats really fucked up</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.6947</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>were fucking free</td>\n",
       "      <td>0.957807</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you were really sick and your mother wanted me...</td>\n",
       "      <td>0.973515</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>you was really sick and your mother wanted me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a nice bowl of soup a little blow job from mél...</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>a little blow job from mélanie youll see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shit clayton run</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>shit clayton run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Toxic style    Before   After  \\\n",
       "0                               i threw them all out  0.908439  0.6947   \n",
       "1  the background is that our thing is cool and p...  0.986022  0.1955   \n",
       "2   nothing yet but i want you to know i smell a rat  0.957481  0.1968   \n",
       "3      could you not appreciate what you fucking had  0.998181  0.6947   \n",
       "4                     your destruction is inevitable  0.715417  0.1395   \n",
       "5                             thats really fucked up  0.999102  0.6947   \n",
       "6                                  were fucking free  0.957807  0.0263   \n",
       "7  you were really sick and your mother wanted me...  0.973515  0.8552   \n",
       "8  a nice bowl of soup a little blow job from mél...  0.991525  0.0821   \n",
       "9                                   shit clayton run  0.999473  0.2306   \n",
       "\n",
       "                                         Translation  \n",
       "0                                                  y  \n",
       "1  Our thing is cool and popular and harvard conn...  \n",
       "2                                     i smell a rat.  \n",
       "3    Können Sie nicht wissen, was Sie gefuckt haben?  \n",
       "4         your destruction destruction is inevitable  \n",
       "5                                                     \n",
       "6                                               free  \n",
       "7  you was really sick and your mother wanted me ...  \n",
       "8           a little blow job from mélanie youll see  \n",
       "9                                   shit clayton run  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the scores\n",
    "scores = pd.DataFrame(list(zip(inputs, input_score, pred_scores, predicted)), index=None, columns=['Toxic style', 'Before', 'After', 'Translation'])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
